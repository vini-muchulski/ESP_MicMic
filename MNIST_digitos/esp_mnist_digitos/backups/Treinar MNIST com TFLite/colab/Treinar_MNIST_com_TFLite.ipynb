{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDfVpfOZOzy1",
        "outputId": "0a52a753-5d31-468f-e1bb-aa10cad50137"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# 1. Dados ────────────────────────────────────────────────────────────────\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0          # normaliza\n",
        "x_train = x_train[..., None].astype(\"float32\")             # (28,28)→(28,28,1)\n",
        "x_test  = x_test[..., None].astype(\"float32\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Supondo que x_train e y_train já existam (já normalizados como float32 e com shape (28,28,1))\n",
        "# 1. Escolhe um índice aleatório\n",
        "idx = random.randint(0, x_train.shape[0] - 1)\n",
        "\n",
        "# 2. Recupera a imagem e o rótulo\n",
        "img = x_train[idx].squeeze()      # squeeze() transforma (28,28,1) em (28,28)\n",
        "label = y_train[idx]\n",
        "\n",
        "# 3. Plota\n",
        "plt.figure(figsize=(4,4))\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.title(f\"Rótulo: {label}\")\n",
        "plt.axis('off')   # desliga os eixos para ficar mais limpo\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "fO1ZamD8Pgqp",
        "outputId": "baefc123-b666-49a2-f04f-cb5034593ce3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treino Modelo"
      ],
      "metadata": {
        "id": "jNcS1vaEO_FM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input((28, 28, 1)),\n",
        "    tf.keras.layers.Conv2D(32, 3, activation=\"relu\"),\n",
        "    tf.keras.layers.MaxPool2D(),\n",
        "    tf.keras.layers.Conv2D(64, 3, activation=\"relu\"),\n",
        "    tf.keras.layers.MaxPool2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "bew8SRJtO5Aj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train,\n",
        "          epochs=5, batch_size=128,\n",
        "          validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQ63PoeAPE_H",
        "outputId": "c25ce1de-4df9-447e-e01a-a44ee0d6f5a6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.8475 - loss: 0.5190 - val_accuracy: 0.9802 - val_loss: 0.0637\n",
            "Epoch 2/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9805 - loss: 0.0628 - val_accuracy: 0.9863 - val_loss: 0.0469\n",
            "Epoch 3/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9876 - loss: 0.0402 - val_accuracy: 0.9852 - val_loss: 0.0502\n",
            "Epoch 4/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9898 - loss: 0.0328 - val_accuracy: 0.9877 - val_loss: 0.0369\n",
            "Epoch 5/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9921 - loss: 0.0245 - val_accuracy: 0.9883 - val_loss: 0.0398\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fc16598d590>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Acurácia de teste: {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5-VLf4HPmLq",
        "outputId": "a547cc62-ff0e-4206-9cbd-38c9e1f180f5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia de teste: 0.9899\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conversão p/ TensorFlow Lite"
      ],
      "metadata": {
        "id": "V2hYnM7ZPrES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n"
      ],
      "metadata": {
        "id": "a7HITC4YPnOu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]"
      ],
      "metadata": {
        "id": "m_kYXvBFP0Q1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_model = converter.convert()\n",
        "open(\"mnist_cnn.tflite\", \"wb\").write(tflite_model)\n",
        "print(\"Modelo salvo em mnist_cnn.tflite\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuMpaqvaPzND",
        "outputId": "b162a383-75c1-47e2-cf95-302b8cfce01b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmpuxhosq_r'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  140468609548368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140468609551824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140468609555280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140468609554128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140468609554320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140468609553936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140468609551440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140468609554704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Modelo salvo em mnist_cnn.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# índice da imagem no batch de teste\n",
        "index = 8\n",
        "\n",
        "# prepara o sample e recupera o rótulo verdadeiro\n",
        "sample = x_test[index : index+1]      # shape (1, 28, 28, 1)\n",
        "true_label = y_test[index]            # rótulo “verdadeiro”\n",
        "\n",
        "print(\"Classe verdadeira:\", true_label)\n",
        "\n",
        "# faz inference TFLite\n",
        "interpreter = tf.lite.Interpreter(model_path=\"mnist_cnn.tflite\")\n",
        "#interpreter = tf.lite.Interpreter(model_path=\"mnist_cnn_int8.tflite\")\n",
        "\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_idx  = interpreter.get_input_details()[0][\"index\"]\n",
        "output_idx = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "interpreter.set_tensor(input_idx, sample)\n",
        "interpreter.invoke()\n",
        "pred = interpreter.get_tensor(output_idx)\n",
        "\n",
        "print(\"Dígito previsto:\", np.argmax(pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LViOWRlDP3a2",
        "outputId": "f9096397-ab41-4387-8f90-5356b338b3da"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classe verdadeira: 5\n",
            "Dígito previsto: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rep_data():\n",
        "    for imgs in tf.data.Dataset.from_tensor_slices(x_train).batch(100).take(100):\n",
        "        yield [imgs]                       # 10 000 amostras ~ suficiente\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = rep_data          # calibragem\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type  = tf.uint8           # ou int8\n",
        "converter.inference_output_type = tf.uint8\n",
        "tflite_quant = converter.convert()\n",
        "open(\"mnist_cnn_int8.tflite\", \"wb\").write(tflite_quant)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooomyGfeQKgE",
        "outputId": "67550402-2b8d-496b-ed79-aec3ef68f027"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmpqh7b6_06'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  140468609548368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140468609551824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140468609555280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140468609554128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140468609554320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140468609553936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140468609551440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  140468609554704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/convert.py:997: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235600"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}